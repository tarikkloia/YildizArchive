package main

import (
	"bufio"
	"context"
	"database/sql"
	"github.com/aws/aws-sdk-go-v2/aws"
	"github.com/aws/aws-sdk-go-v2/credentials"
	"github.com/aws/aws-sdk-go-v2/service/s3"
	"io"
	"log"
	//"database/sql"
	"fmt"
	"github.com/aws/aws-sdk-go-v2/config"
	"github.com/jackc/pgx/v5"

	"github.com/aws/aws-lambda-go/lambda"
	"github.com/jackc/pgx/v5/pgconn"
	_ "github.com/lib/pq"
	"os"
	"path/filepath"
	"regexp"
	"strconv"
	"strings"
	"sync"
	"time"
)

const total = 10
const timeoutSec = 9000

// const host = "http://localhost:4566"
const host = "http://host.docker.internal:4566"

type s3file struct {
	Bucket string
	Key    string
}
type Event struct {
	Args []string `json:"args"`
}

func handler(ctx context.Context, event Event) (string, error) {
	if len(event.Args) < 4 {
		fmt.Println("Usage: ./app <parallel_count> <dbname> <sql_file> <log_prefix> [name]")
		return "", nil
	}
	fmt.Println("START")
	parallelCount, _ := strconv.Atoi(event.Args[0])
	if parallelCount < 1 {
		parallelCount = 1
	}
	if parallelCount > 10 {
		parallelCount = 10
	}
	db := event.Args[1]
	sqlPath := event.Args[2]
	logPrefix := event.Args[3]
	//name := "job"
	//if len(os.Args) >= 6 {
	//	name = os.Args[5]
	//}

	const total = 10
	const timeoutSec = 9000
	fmt.Println(total)
	fmt.Println(parallelCount)
	fmt.Println(db)
	fmt.Println(sqlPath)
	fmt.Println(logPrefix)

	sqlBlock, err := getSqlFromS3(ctx, "scripts", sqlPath)
	if err != nil {
		fmt.Println("hata")
		fmt.Println(err)
		return "", err

	}
	//fmt.Println(sqlBlock)

	connStr := "host=host.docker.internal port=5432 user=postgres password=1 dbname=destination_db sslmode=disable"

	//con, errDb := sql.Open("postgres", connStr)
	//if errDb != nil {
	//	log.Fatal("DB connection failed:", err)
	//}
	//defer func(con *sql.DB) {
	//	err := con.Close()
	//	if err != nil {
	//
	//	}
	//}(con)
	fmt.Println("xxxx")
	fmt.Println(33)
	filename := filepath.Base(sqlPath)
	ext := filepath.Ext(filename)
	nameOnly := filename[:len(filename)-len(ext)]
	logFile, err := runParallelSQL(ctx, connStr, db, nameOnly, sqlBlock, logPrefix, total, parallelCount, timeoutSec)
	if err != nil {
		//notifySlack("ERROR", name, "SQL çalıştırılamadı", err.Error())
		return "", nil
	}

	//totalCount, duration, _ := parseSummary(logFile)

	statusSummary := ""
	data, _ := os.ReadFile(logFile)
	lines := strings.Split(string(data), "\n")
	for _, line := range lines {
		if matched, _ := regexp.MatchString(`(?i)error|fail`, line); matched {
			statusSummary += line + "\n"
		}
	}

	//stat := "Succeeded"
	//alertType := "Success"
	//if statusSummary != "" {
	//	stat = "Failed"
	//	alertType = "Error"
	//}

	//message := fmt.Sprintf("Status : %s\nParallel : %d\n\nTotal Count : %d\nDuration : %s\n\nServer : %s\nLog : %s",
	//	stat, parallelCount, totalCount, duration, getLocalIP(), logFile)

	//notifySlack(alertType, name, message, statusSummary)
	return "Success", nil
}
func runScript(ctx context.Context, db *sql.DB, script string, id int) {
	conn, err := db.Conn(ctx)
	if err != nil {
		log.Printf("Connection error [worker %d]: %v\n", id, err)
		return
	}
	defer conn.Close()

	tx, err := conn.BeginTx(ctx, nil)
	if err != nil {
		log.Printf("BeginTx failed [worker %d]: %v\n", id, err)
		return
	}

	_, err = tx.ExecContext(ctx, script)
	if err != nil {
		log.Printf("Exec failed [worker %d]: %v\n", id, err)
		tx.Rollback()
		return
	}

	if err := tx.Commit(); err != nil {
		log.Printf("Commit failed [worker %d]: %v\n", id, err)
		return
	}

	log.Printf("Worker %d: script executed successfully.", id)
}
func getS3Client(ctx context.Context) (*s3.Client, error) {
	cfg, err := config.LoadDefaultConfig(ctx,
		config.WithRegion("us-east-1"),
		config.WithCredentialsProvider(
			aws.NewCredentialsCache(
				credentials.NewStaticCredentialsProvider("test", "test", ""),
			),
		),
	)
	if err != nil {
		return nil, err
	}

	s3Client := s3.NewFromConfig(cfg, func(o *s3.Options) {
		o.EndpointResolver = s3.EndpointResolverFromURL(host)
		o.UsePathStyle = true // localStack için gerekli
	})
	return s3Client, nil
}
func getSqlFromS3(ctx context.Context, bucket string, fileName string) (string, error) {

	file := s3file{Bucket: "scripts", Key: "order_archive_daily.sql"}

	client, err := getS3Client(ctx)
	if err != nil {
		return "AWS Config not loaded.", err
	}
	getObj, err := client.GetObject(ctx, &s3.GetObjectInput{
		Bucket: &file.Bucket,
		Key:    &file.Key,
	})
	if err != nil {
		return "S3 file could not be retrieved", err
	}
	defer getObj.Body.Close()

	bodyBytes, err := io.ReadAll(getObj.Body)
	if err != nil {
		return "S3 file could not be read", err
	}
	sqlContent := string(bodyBytes)

	return sqlContent, nil
}
func runParallelSQL(ctx context.Context, connStr string, db, name string, sql string, logPrefix string, total, parallel int, timeoutSec int) (string, error) {
	//tm := time.Now().Format("20060102T150405000")
	fmt.Println("runParallelSQL")
	fmt.Println(parallel)
	tm := time.Now().Format("20060102T150405") + fmt.Sprintf("%03d", time.Now().Nanosecond()/1e6)
	//fmt.Println("time.Now().Nanosecond()")
	//fmt.Println(tm)
	var wg sync.WaitGroup
	chunkSize := total / parallel
	remainder := total % parallel
	uniqID := fmt.Sprintf("%d", parallel)
	date := time.Now().Format("20060102T150405000")
	mergedLog := fmt.Sprintf("%s_%s_%s.log", logPrefix, uniqID, date)
	lb := 0
	logFiles := make([]string, 0)

	for i := 0; i < parallel; i++ {
		extra := 0
		if i < remainder {
			extra = 1
		}
		count := chunkSize + extra
		up := lb + count - 1
		logFile := fmt.Sprintf("%s_%s_%d_%d_%d_%s.log", logPrefix, uniqID, i, lb, up, date)
		logFiles = append(logFiles, logFile)

		wg.Add(1)
		go func(lb, up int, logFile string) {
			defer wg.Done()

			//tmpfile, err := os.CreateTemp("", fmt.Sprintf("tmp-%s-%d-%d-%s-*.log", name, lb, up, time.Now().Format("20060102_150405.000")))
			//tt := fmt.Sprintf("order_archive_daily_%d_%d_%d,%s.log", total, lb, up, time.Now().Format("20060102T150405000"))
			//fmt.Println(tt)

			tmpfile, err := os.CreateTemp("", getTempFilename(name, tm, lb, up))

			if err != nil {
				log.Fatalf("[Worker %d-%d] Temp file error: %v", lb, up, err)
			}
			//defer os.Remove(tmpfile.Name())
			defer tmpfile.Close()

			parseConfig, err := pgx.ParseConfig(connStr)
			if err != nil {
				log.Fatalf("parseConfig parse failed: %v", err)
			}
			parseConfig.RuntimeParams["client_min_messages"] = "info"
			parseConfig.Config.OnNotice = func(c *pgconn.PgConn, n *pgconn.Notice) {
				//fmt.Printf("%d-%d %s\n", lb, up, n.Message)
				msg := fmt.Sprintf("%s\n", n.Message)
				if _, err := tmpfile.WriteString(msg); err != nil {
					log.Printf("write failed: %v", err)
				}
			}

			conn, err := pgx.ConnectConfig(ctx, parseConfig)
			if err != nil {
				log.Fatal("connect:", err)
			}
			defer conn.Close(ctx)
			sql := strings.ReplaceAll(strings.ReplaceAll(sql, "@lb@", strconv.Itoa(lb)), "@up@", strconv.Itoa(up))
			aa, err := conn.Exec(ctx, sql)
			if err != nil {
				return
			}

			fmt.Println(aa)

		}(lb, up, logFile)

		lb = up + 1
	}

	wg.Wait()
	file := mergeLog(name, tm)
	if err := uploadToS3FromFile(ctx, "scripts", fmt.Sprintf("logs/%s_%d_%s.log", name, total, tm), file.Name()); err != nil {
		log.Printf("upload error: %v", err)
		//log.Fatalf("upload error: %v", err)
		//time.Sleep(4 * time.Minute)
	}
	// Merge logs
	//mergedF, _ := os.Create(mergedLog)
	//defer mergedF.Close()
	//
	//for _, f := range logFiles {
	//	content, _ := os.ReadFile(f)
	//	mergedF.WriteString(fmt.Sprintf("INFO: %s\n", filepath.Base(f)))
	//	mergedF.Write(content)
	//	os.Remove(f)
	//}

	return mergedLog, nil
}
func getTempFilename(name string, tm string, lb int, up int) string {

	return fmt.Sprintf("%s_%d_%d_", getTemp(name, tm), lb, up)
}

type logStatus struct {
	name string
	err  bool
}

func getTemp(name string, tm string) string {
	return fmt.Sprintf("tmp_%s_%d_%s", name, total, tm)
}
func mergeLog(name string, tm string) *os.File {
	logStat := &[]logStatus{}
	keywords := []string{"err", "error", "fail", "failed"}
	tmp := getTemp(name, tm)
	tmpDir := os.TempDir()

	tmpfile, err := os.CreateTemp("", fmt.Sprintf("%s.log", tmp))
	if err != nil {
		log.Fatalf("Temp file error: %v", err)
	}
	defer func(name string) {
		//err := os.Remove(name)
		err := tmpfile.Close()
		if err != nil {

		}
	}(tmpfile.Name())

	files, err := filepath.Glob(filepath.Join(tmpDir, fmt.Sprintf("%s_*", tmp)))
	if err != nil {
		log.Fatal(err)
	}
	var totalCount int
	var maxDuration time.Duration

	for _, f := range files {

		_, err = tmpfile.WriteString(fmt.Sprintf("%s %s\n\n", time.Now().Format("2006-01-02 15:04:05 :"), f))
		if err != nil {
			return nil
		}

		fmt.Println("Reading:", f)
		in, err := os.Open(f)
		if err != nil {
			log.Printf("Failed to open %s: %v", f, err)
			continue
		}

		// SATIR SATIR OKUYORUZ, KELİME KONTROLÜ İÇİN
		//scanner := bufio.NewScanner(in)
		//var contentBuilder strings.Builder
		//
		//for scanner.Scan() {
		//	line := scanner.Text()
		//	contentBuilder.WriteString(line + "\n")
		//
		//	lower := strings.ToLower(line)
		//	for _, kw := range keywords {
		//		if strings.Contains(lower, kw) {
		//			hasErr = true
		//			log.Printf("Warning: '%s' contains keyword '%s'", f, kw)
		//			break
		//		}
		//	}
		//}

		//hasErr := false
		//var contentBuilder strings.Builder
		//reader := bufio.NewReader(in)
		//for {
		//	line, _, err := reader.ReadLine()
		//	if err == io.EOF {
		//		break
		//	}
		//	text := string(line)
		//	contentBuilder.WriteString(text + "\n")
		//
		//	lower := strings.ToLower(text)
		//	for _, kw := range keywords {
		//		if strings.Contains(lower, kw) {
		//			hasErr = true
		//			log.Printf("Warning: '%s' contains keyword '%s'", f, kw)
		//			break
		//		}
		//	}
		//}

		//*****
		hasErr := false
		var contentBuilder strings.Builder
		reader := bufio.NewReader(in)

		for {
			line, _, err := reader.ReadLine()
			if err == io.EOF {
				break
			}
			text := string(line)
			contentBuilder.WriteString(text + "\n")

			lower := strings.ToLower(text)
			for _, kw := range keywords {
				if strings.Contains(lower, kw) {
					hasErr = true
					log.Printf("Warning: '%s' contains keyword '%s'", f, kw)
					break
				}
			}

			if strings.Contains(text, "Total") {
				// bir sonraki satırı oku
				nextLine, _, err := reader.ReadLine()
				if err != nil {
					break
				}
				nextText := string(nextLine)
				contentBuilder.WriteString(nextText + "\n")

				// ilk sayıyı al
				reCount := regexp.MustCompile(`:\s*(\d+)\s+\w+\(s\)`)
				countMatch := reCount.FindStringSubmatch(nextText)
				if len(countMatch) >= 2 {
					count, _ := strconv.Atoi(countMatch[1])
					totalCount += count
				}

				// Duration'u al
				reDuration := regexp.MustCompile(`Duration\s*:\s*([0-9]{2}):([0-9]{2}):([0-9]{2})`)
				durMatch := reDuration.FindStringSubmatch(nextText)
				if len(durMatch) == 4 {
					hh, _ := strconv.Atoi(durMatch[1])
					mm, _ := strconv.Atoi(durMatch[2])
					ss, _ := strconv.Atoi(durMatch[3])

					duration := time.Duration(hh)*time.Hour + time.Duration(mm)*time.Minute + time.Duration(ss)*time.Second
					if duration > maxDuration {
						maxDuration = duration
					}
				}
			}
		}
		//*****
		*logStat = append(*logStat, logStatus{name: f, err: hasErr})
		_, err = tmpfile.WriteString(contentBuilder.String())
		in.Close()
		if err != nil {
			log.Printf("Failed to write content of %s: %v", f, err)
			continue
		}
		//_, err = io.Copy(tmpfile, in)
		//in.Close()
		//if err != nil {
		//	log.Printf("Failed to copy %s: %v", f, err)
		//	continue
		//}

		// Dosyayı birleştirdikten sonra sil
		err = os.Remove(in.Name())
		if err != nil {
			log.Printf("Failed to delete %s: %v", f, err)
		} else {
			fmt.Println("Deleted:", f)
		}
		_, err = tmpfile.WriteString("\n")
		if err != nil {
			return nil
		}
	}
	//rand.Seed(time.Now().UnixNano()) // rastgelelik için seed

	//// 1 saniye ile 1 saat arası süre (1s - 3600s)
	//randomMillis := rand.Int63n(3600_000) + 1000 // 1000 ms = 1s
	//randomDuration := time.Duration(randomMillis) * time.Millisecond
	//maxDuration = randomDuration
	_, err = tmpfile.WriteString(fmt.Sprintf("\nTotal Count: %d\nTotal Duration: %02d:%02d:%02d.%03d", totalCount,
		int(maxDuration.Hours()),
		int(maxDuration.Minutes())%60,
		int(maxDuration.Seconds())%60,
		int(maxDuration.Milliseconds())%1000))
	if err != nil {
		return nil
	}
	log.Printf("Total Count: %d", totalCount)
	log.Printf("Total Duration: %s", maxDuration.String()) // örn: "7h10m0s"
	//time.Sleep(4 * time.Minute)
	return tmpfile

}
func uploadToS3FromFile(ctx context.Context, bucket, key, filePath string) error {

	client, err := getS3Client(ctx)
	if err != nil {

		return err

	}

	f, err := os.Open(filePath)
	if err != nil {
		return fmt.Errorf("open temp file: %w", err)
	}

	defer func(name string) {
		err := f.Close()
		if err != nil {

		}
		err = os.Remove(name)
		if err != nil {

		}
	}(f.Name())

	_, err = client.PutObject(ctx, &s3.PutObjectInput{
		Bucket: aws.String(bucket),
		Key:    aws.String(key),
		Body:   f,
	})
	if err != nil {
		return fmt.Errorf("s3 upload error: %w", err)
	}

	return nil
}
func parseSummary(logFile string) (totalCount int, duration string, err error) {
	data, err := os.ReadFile(logFile)
	if err != nil {
		return
	}

	text := string(data)
	re := regexp.MustCompile(`Total Count: (\d+)`)
	match := re.FindStringSubmatch(text)
	if len(match) == 2 {
		totalCount, _ = strconv.Atoi(match[1])
	}

	re = regexp.MustCompile(`Duration: ([0-9:.]+)`)
	match = re.FindStringSubmatch(text)
	if len(match) == 2 {
		duration = match[1]
	}
	return
}
func main() {
	lambda.Start(handler)
	//handler(context.Background())
}
