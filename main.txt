package main

import (
	"bufio"
	"context"
	"errors"
	"fmt"
	//"github.com/aws/aws-lambda-go/lambda"

	//"github.com/aws/aws-lambda-go/lambda"
	"github.com/aws/aws-sdk-go-v2/aws"
	"github.com/aws/aws-sdk-go-v2/config"
	"github.com/aws/aws-sdk-go-v2/credentials"
	"github.com/aws/aws-sdk-go-v2/service/s3"
	"github.com/jackc/pgx/v5"
	"github.com/jackc/pgx/v5/pgconn"
	_ "github.com/lib/pq"
	"io"
	"log"
	"os"
	"path/filepath"
	"regexp"
	"strconv"
	"strings"
	"sync"
	"time"
)

const total = 10

// const host = "http://localhost:4566"
const host = "http://host.docker.internal:4566"

type Logger interface {
	Log(message string)

	Logf(format string, v ...any)
	CreateLogFile(dir string, file string) (*os.File, error)
}

//type ConsoleLogger struct{}
//
//func (c ConsoleLogger) Log(message string) {
//	log.Println(message)
//	//	fmt.Println( message)
//}
//func (c ConsoleLogger) Logf(format string, v ...any) {
//	log.Printf(format, v)
//	//	fmt.Println( message)
//}
//func (c ConsoleLogger) CreateLogFile(dir string, file string) (*os.File, error) {
//	return nil, nil
//}

type FileLogger struct {
	tmpFile  *os.File
	i        int
	parallel int
}

func (lg FileLogger) Log(message string) {
	if _, err := lg.tmpFile.WriteString(message + "\n"); err != nil {
		log.Printf("write failed: %v", err)
	}
	var cmsg string
	if len(message) > 22 {
		//cmsg=fmt.Println(n.Message[5:])
		cmsg = fmt.Sprintf(": Batch %d/%d : %s", lg.i+1, lg.parallel, message[22:])
	} else {
		cmsg = fmt.Sprintf(": Batch %d/%d : %s", lg.i+1, lg.parallel, message)
	}
	log.Println(cmsg)
}
func NewFileLogger(name string, i int, parallel int, tm string, lb int, up int) (*FileLogger, error) {
	lg, err := os.CreateTemp("", getTempFilename(name, tm, lb, up))
	if err != nil {
		return nil, err
	}
	//tmpfile, err := os.CreateTemp("", getTempFilename(event.Name, tm, lb, up))
	return &FileLogger{
		tmpFile:  lg,
		i:        i,
		parallel: parallel,
	}, nil
}
func (c FileLogger) Logf(format string, v ...any) {
	log.Printf(format, v)
	//	fmt.Println( message)
}
func (c FileLogger) CreateLogFile(dir string, file string) (*os.File, error) {
	tmp, err := os.CreateTemp(dir, file)
	if err != nil {
		return nil, err
	}
	return tmp, nil
}

type Service struct {
	logger Logger
}

func NewService(logger Logger) *Service {
	return &Service{logger: logger}
}
func (s *Service) Println(txt string) {
	if s != nil {
		s.logger.Log(txt)
	} else {
		log.Println(txt)
	}

}
func (s *Service) PrintlnWithTime(txt string) {
	if s != nil {
		s.logger.Log(fmt.Sprintf("%s : %s", time.Now().Format("2006-01-02 15:04:05"), txt))
	} else {
		log.Println(txt)
	}

}
func (s *Service) Printf(format string, v ...any) {
	if s != nil {
		s.logger.Logf(format, v)
	} else {
		log.Printf(format, v)
	}
}

func (s *Service) CreateLogFile(dir string, file string) (*os.File, error) {
	return s.logger.CreateLogFile(dir, file)
}

type s3file struct {
	Bucket string
	Key    string
}

type Event struct {
	Parallel   int        `json:"parallel"`
	SqlFile    string     `header:"sqlFile"`
	LogPrefix  string     `header:"logPrefix"`
	Name       string     `json:"name"`
	S3Log      bool       `json:"s3Log"`
	SqlBucket  Bucket     `json:"sqlBucket"`
	LogBucket  Bucket     `json:"logBucket"`
	Slack      Slack      `json:"slack"`
	Connection Connection `json:"connection"`
}
type Bucket struct {
	Name   string `json:"name"`
	Key string `json:"folder"`
}
type Slack struct {
	Url     string `json:"url"`
	Channel string `json:"channel"`
}
type Connection struct {
	Host         string `json:"host"`
	Port         int    `json:"port"`
	User         string `json:"user"`
	Password     string `json:"password"`
	DatabaseName string `json:"databaseName"`
}

func (e *Event) Init() error {
	if e.Connection.Port == 0 {
		e.Connection.Port = 5432
	}

	if e.Connection.Host == "" {
		log.Println("host field is required")
		return errors.New("missing host")
	}
	if e.Connection.User == "" {
		log.Println("user not set,defaulting to postgres")
		e.Connection.User = "postgres"
	}
	if e.Connection.Password == "" {
		log.Println("password field is required")
		return errors.New("missing password")
	}
	if e.Name == "" {
		filename := filepath.Base(e.SqlFile)
		ext := filepath.Ext(filename)
		e.Name = filename[:len(filename)-len(ext)]
	}
	return nil

}
func handler(ctx context.Context, event Event) (string, error) {

	log.Println("Process started")
	if err := event.Init(); err != nil {
		return "", err
	}

	if event.Parallel < 1 {
		event.Parallel = 1
	}
	if event.Parallel > 10 {
		event.Parallel = 10
	}

	const total = 10
	const timeoutSec = 9000

	sqlBlock, err := getSqlFromS3(ctx, &event)
	if err != nil {
		log.Println(fmt.Sprintf("Cannot get sql from %s", event.SqlFile))
		log.Println(err.Error())
		return "", err

	}

	connStr := fmt.Sprintf("host=%s port=%d user=%s password=%s dbname=%s sslmode=disable",
		event.Connection.Host, event.Connection.Port, event.Connection.User, event.Connection.Password, event.Connection.DatabaseName)

	_, err = runParallelSQL(ctx, connStr, sqlBlock, &event)
	if err != nil {
		//notifySlack("ERROR", name, "SQL çalıştırılamadı", err.Error())
		return "", nil
	}

	//notifySlack(alertType, name, message, statusSummary)
	log.Println("Process completed")
	return "Success", nil
}

func getS3Client(ctx context.Context) (*s3.Client, error) {
	cfg, err := config.LoadDefaultConfig(ctx,
		config.WithRegion("us-east-1"),
		config.WithCredentialsProvider(
			aws.NewCredentialsCache(
				credentials.NewStaticCredentialsProvider("test", "test", ""),
			),
		),
	)
	if err != nil {
		return nil, err
	}

	s3Client := s3.NewFromConfig(cfg, func(o *s3.Options) {
		o.EndpointResolver = s3.EndpointResolverFromURL(host)
		o.UsePathStyle = true // localStack için gerekli
	})
	return s3Client, nil
}
func getSqlFromS3(ctx context.Context, event *Event) (string, error) {

	file := s3file{Bucket: event.SqlBucket.Name, Key: event.SqlFile}

	client, err := getS3Client(ctx)
	if err != nil {
		return "AWS Config not loaded.", err
	}
	getObj, err := client.GetObject(ctx, &s3.GetObjectInput{
		Bucket: &file.Bucket,
		Key:    &file.Key,
	})
	if err != nil {
		return "S3 file could not be retrieved", err
	}
	defer getObj.Body.Close()

	bodyBytes, err := io.ReadAll(getObj.Body)
	if err != nil {
		return "S3 file could not be read", err
	}
	sqlContent := string(bodyBytes)

	return sqlContent, nil
}

// logFile, err := runParallelSQL(ctx, connStr, db, nameOnly, sqlBlock, logPrefix, total, parallelCount, timeoutSec)
// func runParallelSQL(ctx context.Context, connStr string, db, name string, sql string, logPrefix string, total, parallel int, timeoutSec int) (string, error)
func runParallelSQL(ctx context.Context, connStr string, sql string, event *Event) (string, error) {

	tm := time.Now().Format("20060102T150405") + fmt.Sprintf("%03d", time.Now().Nanosecond()/1e6)

	var wg sync.WaitGroup
	chunkSize := total / event.Parallel
	remainder := total % event.Parallel
	uniqID := fmt.Sprintf("%d", event.Parallel)
	date := time.Now().Format("20060102T150405000")
	mergedLog := fmt.Sprintf("%s_%s_%s.log", event.LogPrefix, uniqID, date)
	lb := 0
	logFiles := make([]string, 0)

	for i := 0; i < event.Parallel; i++ {
		extra := 0
		if i < remainder {
			extra = 1
		}
		count := chunkSize + extra
		up := lb + count - 1
		logFile := fmt.Sprintf("%s_%s_%d_%d_%d_%s.log", event.LogPrefix, uniqID, i, lb, up, date)
		logFiles = append(logFiles, logFile)

		wg.Add(1)
		go func(lb, up int, logFile string) {
			defer wg.Done()

			var logService *Service
			//logService := NewService(logger)
			//logger = ConsoleLogger{}
			//tmpfile, err := os.CreateTemp("", getTempFilename(event.Name, tm, lb, up))

			//logger = FileLogger{tmpFile: tmpfile, i: i, parallel: event.Parallel}

			if event.S3Log {
				logger, err := NewFileLogger(event.Name, i, event.Parallel, tm, lb, up)
				if err != nil {
					log.Fatalf("[Worker %d-%d] Temp file error: %v", lb, up, err)
				}
				logService = NewService(logger)
			}
			//logService.Println("Process started")
			//logService.Println(fmt.Sprintf("Batch %d/%d started", i+1, event.Parallel))
			logService.PrintlnWithTime("Started")
			//logService.Println(fmt.Sprintf("Batch %d/%d started", i, event.Parallel))
			///tmpfile, err := os.CreateTemp("", getTempFilename(event.Name, tm, lb, up))
			//tmpfile, err := logService.CreateLogFile("", getTempFilename(event.Name, tm, lb, up))

			parseConfig, err := pgx.ParseConfig(connStr)
			if err != nil {
				log.Fatalf("parseConfig parse failed: %v", err)
			}
			parseConfig.RuntimeParams["client_min_messages"] = "info"
			parseConfig.Config.OnNotice = func(c *pgconn.PgConn, n *pgconn.Notice) {
				logService.Println(fmt.Sprintf("%s", n.Message))
				//cmsg := fmt.Sprintf("Batch %d/%d : %s", i, event.Parallel, n.Message[1:])

				//log.Println(cmsg)
				//if _, err := tmpfile.WriteString(msg); err != nil {
				//	logService.Printf("write failed: %v", err)
				//}
			}

			conn, err := pgx.ConnectConfig(ctx, parseConfig)
			if err != nil {
				log.Fatal("connect:", err)
			}
			defer func(conn *pgx.Conn, ctx context.Context) {
				err := conn.Close(ctx)
				if err != nil {
					return
				}
			}(conn, ctx)

			_, err = conn.Exec(ctx, "set time zone 'Europe/Istanbul';")
			if err != nil {
				return
			}
			sql := strings.ReplaceAll(strings.ReplaceAll(sql, "@lb@", strconv.Itoa(lb)), "@up@", strconv.Itoa(up))
			_, err = conn.Exec(ctx, sql)
			if err != nil {
				logService.Println("Not completed, but records processed before the error were successfully committed.")
				//if _, err := tmpfile.WriteString(fmt.Sprintf("%s : %s\n\n", time.Now().Format("2006-01-02 15:04:05"), err.Error())); err != nil {
				logService.Printf("write failed: %v", err)

				return
			}

		}(lb, up, logFile)

		lb = up + 1
	}

	wg.Wait()

	file := mergeLog(event.Name, tm)
	if file != nil {
		event.LogBucket.Key = fmt.Sprintf("%s/%s_%d_%s.log", event.LogBucket.Key, event.Name, total, tm)
		if err := uploadToS3FromFile(ctx, event, file.Name()); err != nil {
			log.Printf("upload error: %v", err)
		}
	}
	// Merge logs
	//mergedF, _ := os.Create(mergedLog)
	//defer mergedF.Close()
	//
	//for _, lg := range logFiles {
	//	content, _ := os.ReadFile(lg)
	//	mergedF.WriteString(fmt.Sprintf("INFO: %s\n", filepath.Base(lg)))
	//	mergedF.Write(content)
	//	os.Remove(lg)
	//}

	return mergedLog, nil
}
func getTempFilename(name string, tm string, lb int, up int) string {

	return fmt.Sprintf("%s_%d_%d_", getTemp(name, tm), lb, up)
}

type logStatus struct {
	name string
	err  bool
}

func getTemp(name string, tm string) string {
	return fmt.Sprintf("tmp_%s_%d_%s", name, total, tm)
}
func mergeLog(name string, tm string) *os.File {
	logStat := &[]logStatus{}
	keywords := []string{"err", "error", "fail", "failed"}
	tmp := getTemp(name, tm)
	tmpDir := os.TempDir()
	files, err := filepath.Glob(filepath.Join(tmpDir, fmt.Sprintf("%s_*", tmp)))
	if err != nil {
		log.Fatal(err)
	}
	if files != nil {

		tmpfile, err := os.CreateTemp("", fmt.Sprintf("%s.log", tmp))
		if err != nil {
			log.Fatalf("Temp file error: %v", err)
		}
		defer func(name string) {
			//err := os.Remove(name)
			err := tmpfile.Close()
			if err != nil {

			}
		}(tmpfile.Name())

		var totalCount int
		var maxDuration time.Duration

		for _, lg := range files {

			_, err = tmpfile.WriteString(fmt.Sprintf("%s %s\n\n", time.Now().Format("2006-01-02 15:04:05 :"), lg))
			if err != nil {
				return nil
			}

			//log.Println(fmt.Sprintf("Reading: %s", lg))
			in, err := os.Open(lg)
			if err != nil {
				log.Printf("Failed to open %s: %v", lg, err)
				continue
			}

			// SATIR SATIR OKUYORUZ, KELİME KONTROLÜ İÇİN
			//scanner := bufio.NewScanner(in)
			//var contentBuilder strings.Builder
			//
			//for scanner.Scan() {
			//	line := scanner.Text()
			//	contentBuilder.WriteString(line + "\n")
			//
			//	lower := strings.ToLower(line)
			//	for _, kw := range keywords {
			//		if strings.Contains(lower, kw) {
			//			hasErr = true
			//			logService.Printf("Warning: '%s' contains keyword '%s'", lg, kw)
			//			break
			//		}
			//	}
			//}

			//hasErr := false
			//var contentBuilder strings.Builder
			//reader := bufio.NewReader(in)
			//for {
			//	line, _, err := reader.ReadLine()
			//	if err == io.EOF {
			//		break
			//	}
			//	text := string(line)
			//	contentBuilder.WriteString(text + "\n")
			//
			//	lower := strings.ToLower(text)
			//	for _, kw := range keywords {
			//		if strings.Contains(lower, kw) {
			//			hasErr = true
			//			logService.Printf("Warning: '%s' contains keyword '%s'", lg, kw)
			//			break
			//		}
			//	}
			//}

			//*****
			hasErr := false
			var contentBuilder strings.Builder
			reader := bufio.NewReader(in)

			for {
				line, _, err := reader.ReadLine()
				if err == io.EOF {
					break
				}
				text := string(line)
				if strings.Contains(text, "Completed") {
					break
				}
				contentBuilder.WriteString(text + "\n")

				lower := strings.ToLower(text)
				for _, kw := range keywords {
					if strings.Contains(lower, kw) {
						hasErr = true
						log.Printf("Warning: '%s' contains keyword '%s'", lg, kw)
						break
					}
				}

				// ilk sayıyı al
				reCount := regexp.MustCompile(`:\s*(\d+)\s+\w+\(s\)`)
				countMatch := reCount.FindStringSubmatch(text)
				if len(countMatch) >= 2 {
					count, _ := strconv.Atoi(countMatch[1])
					totalCount += count
				}

				// Duration'u al
				reDuration := regexp.MustCompile(`Duration\s*:\s*([0-9]{2}):([0-9]{2}):([0-9]{2}).([0-9]+)?`)
				durMatch := reDuration.FindStringSubmatch(text)
				if len(durMatch) == 5 {
					hh, _ := strconv.Atoi(durMatch[1])
					mm, _ := strconv.Atoi(durMatch[2])
					ss, _ := strconv.Atoi(durMatch[3])
					ms, _ := strconv.Atoi(durMatch[4])

					maxDuration = maxDuration + time.Duration(hh)*time.Hour + time.Duration(mm)*time.Minute + time.Duration(ss)*time.Second + time.Duration(ms)*time.Microsecond

				}

				//if strings.Contains(text, "Total") {
				//	// bir sonraki satırı oku
				//	nextLine, _, err := reader.ReadLine()
				//	if err != nil {
				//		break
				//	}
				//	nextText := string(nextLine)
				//	contentBuilder.WriteString(nextText + "\n")
				//
				//	// ilk sayıyı al
				//	reCount := regexp.MustCompile(`:\s*(\d+)\s+\w+\(s\)`)
				//	countMatch := reCount.FindStringSubmatch(nextText)
				//	if len(countMatch) >= 2 {
				//		count, _ := strconv.Atoi(countMatch[1])
				//		totalCount += count
				//	}
				//
				//	// Duration'u al
				//	reDuration := regexp.MustCompile(`Duration\s*:\s*([0-9]{2}):([0-9]{2}):([0-9]{2})`)
				//	durMatch := reDuration.FindStringSubmatch(nextText)
				//	if len(durMatch) == 4 {
				//		hh, _ := strconv.Atoi(durMatch[1])
				//		mm, _ := strconv.Atoi(durMatch[2])
				//		ss, _ := strconv.Atoi(durMatch[3])
				//
				//		duration := time.Duration(hh)*time.Hour + time.Duration(mm)*time.Minute + time.Duration(ss)*time.Second
				//		if duration > maxDuration {
				//			maxDuration = duration
				//		}
				//	}
				//}
			}
			//*****
			*logStat = append(*logStat, logStatus{name: lg, err: hasErr})
			_, err = tmpfile.WriteString(contentBuilder.String())
			in.Close()
			if err != nil {
				log.Printf("Failed to write content of %s: %v", lg, err)
				continue
			}
			//_, err = io.Copy(tmpfile, in)
			//in.Close()
			//if err != nil {
			//	logService.Printf("Failed to copy %s: %v", lg, err)
			//	continue
			//}

			//Dosyayı birleştirdikten sonra sil
			err = os.Remove(in.Name())
			if err != nil {
				log.Printf("Failed to delete %s: %v", lg, err)
			}
			_, err = tmpfile.WriteString("\n")
			if err != nil {
				return nil
			}
		}
		//rand.Seed(time.Now().UnixNano()) // rastgelelik için seed

		//// 1 saniye ile 1 saat arası süre (1s - 3600s)
		//randomMillis := rand.Int63n(3600_000) + 1000 // 1000 ms = 1s
		//randomDuration := time.Duration(randomMillis) * time.Millisecond
		//maxDuration = randomDuration
		_, err = tmpfile.WriteString(fmt.Sprintf("\nTotal Count: %d\nTotal Duration: %02d:%02d:%02d.%03d", totalCount,
			int(maxDuration.Hours()),
			int(maxDuration.Minutes())%60,
			int(maxDuration.Seconds())%60,
			int(maxDuration.Microseconds())%1000000))
		if err != nil {
			return nil
		}

		log.Printf("Total Count: %d", totalCount)
		log.Printf("Total Duration: %s", maxDuration.String()) // örn: "7h10m0s"
		//time.Sleep(4 * time.Minute)
		return tmpfile
	}
	return nil

}
func uploadToS3FromFile(ctx context.Context, event *Event, filePath string) error {

	client, err := getS3Client(ctx)
	if err != nil {

		return err

	}

	lg, err := os.Open(filePath)
	if err != nil {
		return fmt.Errorf("open temp file: %w", err)
	}

	defer func(name string) {
		err := lg.Close()
		if err != nil {

		}
		err = os.Remove(name)
		if err != nil {

		}
	}(lg.Name())

	_, err = client.PutObject(ctx, &s3.PutObjectInput{
		Bucket: aws.String(event.LogBucket.Name),
		Key:    aws.String(event.LogBucket.Key),
		Body:   lg,
	})
	if err != nil {
		return fmt.Errorf("s3 upload error: %w", err)
	}

	return nil
}
func parseSummary(logFile string) (totalCount int, duration string, err error) {
	data, err := os.ReadFile(logFile)
	if err != nil {
		return
	}

	text := string(data)
	re := regexp.MustCompile(`Total Count: (\d+)`)
	match := re.FindStringSubmatch(text)
	if len(match) == 2 {
		totalCount, _ = strconv.Atoi(match[1])
	}

	re = regexp.MustCompile(`Duration: ([0-9:.]+)`)
	match = re.FindStringSubmatch(text)
	if len(match) == 2 {
		duration = match[1]
	}
	return
}
func main() {

	// 1. seçenek: Console logger
	//lambda.Start(handler)
	//return
	event := Event{
		Parallel:  10,
		SqlFile:   "order_archive_daily.sql",
		LogPrefix: "order_archive_daily",
		SqlBucket: Bucket{
			Name: "scripts",
		},
		LogBucket: Bucket{
			Name:   "scripts",
			Key: "logs",
		},
		Slack: Slack{
			Url:     "https://hooks.slack.com/services/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",
			Channel: "test",
		},
		Connection: Connection{
			Host: "host.docker.internal",
			//Port:      5432,
			DatabaseName: "destination_db",
			Password:     "1",
		},
		S3Log: true,
	}

	//5 destination_db order_archive_daily.sql order_archive_daily
	handler(context.Background(), event)
}
